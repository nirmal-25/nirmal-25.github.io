{"componentChunkName":"component---src-pages-index-js","path":"/","result":{"data":{"hero":{"edges":[{"node":{"frontmatter":{"title":"Hello! My name is","name":"Nirmal Amirthalingam","subtitle":"","buttonText":"Contact Me"},"html":"<p>I'm a graduate student passionate about working in Computer Vision, Machine Learning, and Data Science, majoring in Computer Engineering at <a href=\"https://www.vt.edu/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Virginia Tech</a>.</p>\n<p>I did my Bachelor's in Electronics Engineering from <a href=\"https://www.amrita.edu/campus/coimbatore/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Amrita Vishwa Vidyapeetham</a>.</p>\n<p>Currently, I'm looking for Full-Time roles in Data Science, Machine Learning, and Software Development, starting in May 2023.</p>"}}]},"about":{"edges":[{"node":{"frontmatter":{"title":"About Me","avatar":{"childImageSharp":{"fluid":{"tracedSVG":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAATABQDASIAAhEBAxEB/8QAGQABAQADAQAAAAAAAAAAAAAAAAQBAgMF/8QAFgEBAQEAAAAAAAAAAAAAAAAAAgAB/9oADAMBAAIQAxAAAAH0uXDRG9KskybVAn//xAAeEAACAQMFAAAAAAAAAAAAAAAAAgEDBBESISIxMv/aAAgBAQABBQLMitqMjOyFPaeZc9U/Z//EABgRAAIDAAAAAAAAAAAAAAAAAAABEBEh/9oACAEDAQE/AcLHH//EABYRAQEBAAAAAAAAAAAAAAAAABABMf/aAAgBAgEBPwEmH//EABwQAAICAgMAAAAAAAAAAAAAAAABEDERISJBgf/aAAgBAQAGPwKji6jeB47LQjyP/8QAGhABAAIDAQAAAAAAAAAAAAAAAQARICFBUf/aAAgBAQABPyG0jboeqgu1cEFbPI0tB9YAi2f/2gAMAwEAAgADAAAAEOffPv/EABoRAAICAwAAAAAAAAAAAAAAAAARARAhMXH/2gAIAQMBAT8QabEIYjlf/8QAGBEAAgMAAAAAAAAAAAAAAAAAARARITH/2gAIAQIBAT8Qg6iuv//EAB4QAQACAgEFAAAAAAAAAAAAAAEAESExcUFRYYHB/9oACAEBAAE/EEoU8MVm3VZplHFcoEakBlAgYwYagdPtuNstw/SCg27bb7TyT//Z","aspectRatio":1.0542168674698795,"src":"/static/a3f6797051b2a3890f17957d38ef118f/ea4ab/profile_pic.jpg","srcSet":"/static/a3f6797051b2a3890f17957d38ef118f/477ba/profile_pic.jpg 175w,\n/static/a3f6797051b2a3890f17957d38ef118f/06776/profile_pic.jpg 350w,\n/static/a3f6797051b2a3890f17957d38ef118f/ea4ab/profile_pic.jpg 700w,\n/static/a3f6797051b2a3890f17957d38ef118f/3055e/profile_pic.jpg 1050w,\n/static/a3f6797051b2a3890f17957d38ef118f/eff08/profile_pic.jpg 1400w,\n/static/a3f6797051b2a3890f17957d38ef118f/4bd54/profile_pic.jpg 2381w","srcWebp":"/static/a3f6797051b2a3890f17957d38ef118f/89afa/profile_pic.webp","srcSetWebp":"/static/a3f6797051b2a3890f17957d38ef118f/9fca7/profile_pic.webp 175w,\n/static/a3f6797051b2a3890f17957d38ef118f/37a4e/profile_pic.webp 350w,\n/static/a3f6797051b2a3890f17957d38ef118f/89afa/profile_pic.webp 700w,\n/static/a3f6797051b2a3890f17957d38ef118f/78e7a/profile_pic.webp 1050w,\n/static/a3f6797051b2a3890f17957d38ef118f/03d34/profile_pic.webp 1400w,\n/static/a3f6797051b2a3890f17957d38ef118f/5fc35/profile_pic.webp 2381w","sizes":"(max-width: 700px) 100vw, 700px"}}},"skills":["Python","SQL","C/C++","MATLAB","PyTorch","TensorFlow","Tableau","OpenCV","AWS","Docker","JavaScript","HTML/CSS","Flask","Git"]},"html":"<!-- Hello! Interestingly, I got introduced to programming in my freshman year at [Birla Institute Of Technology,  Mesra](https://www.bitmesra.ac.in/) where I completed my Bachelors in Computer Science and Engineering (2016-2020) with [86.3% aggregate](https://drive.google.com/file/d/1G4UBPBP0mvWZLRdkF_EcpmKKGp7_OA8U/view?usp=sharing).\n\nI'm currently working as a developer for **Bell Canada** in the Amdocs Digital Delivery unit. My responsibilty includes Java/Spring based microservices development & testing. \n\nI'm also an [Innovation Agent](https://drive.google.com/file/d/117KS9QnDrcg7dllcAzGz_b7qQPgR3pGs/view?usp=sharing) fostering the culture of creativity and innovation at Amdocs, India.\n\nI have been awarded as Winner in [Innovation Nugget](https://drive.google.com/file/d/1PzTZkXlQV9ldZxqmBbbO94uIqrhSwvcq/view?usp=sharing), Creativity Jam, [Design Thinking Hackathon](https://drive.google.com/file/d/1hXCATvKwzHCvctHtElsqFg5YIqabz22O/view?usp=sharing) and Runners-Up in [Project ICE Fair](https://drive.google.com/file/d/1exB19OoQ5dzU2mg4qbdkNutA25TGBWV3/view?usp=sharing) by Amdocs.\n\nHere is a list of the technologies that I'm familiar with! -->\n<p>Welcome to my portfolio! I have a primary background and strong academic experience in computer vision, machine learning and data science.</p>\n<p>I wish to further develop my skills by working closely on industry-focussed projects, and becoming part of a team that helps build meaningful systems with data that benefit society when looking at the bigger picture. Keep scrolling to learn more about me!</p>\n<!-- and the one thing where even state-of-the-art models fail essentially boils down to is data. Without clean data, there is simply no learning, and I'm trying to focus more on data pre-processing techniques on one hand while also working closely with ML/DL algorithms as part of my research at Virginia Tech.  -->\n<p>Here are some of my technical skills:</p>"}}]},"jobs":{"edges":[{"node":{"frontmatter":{"title":"Deep Learning Researcher","company":"DLRL, VT","range":"Jan 2022 - Present","url":"https://dlib.vt.edu/"},"html":"<ul>\n<li>\n<p>Currently, I'm working with the Digital Libraries Research Laboratory <a href=\"https://dlib.vt.edu/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">DLRL</a> at Virginia Tech to develop an end-to-end deep learning pipeline for information extraction from Virginia Tech’s Electronic Theses and Dissertations <a href=\"https://vtechworks.lib.vt.edu/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">repository</a></p>\n</li>\n<li>\n<p>Researching on incorporating Transformer models for Visual Document Understanding and instance segmentation to include semantics along with visual features</p>\n</li>\n</ul>"}},{"node":{"frontmatter":{"title":"Machine Learning Intern","company":"AreaProbe","range":"May - August 2022","url":"https://areaprobe.com/"},"html":"<ul>\n<li>Developed Catalyst - an object detection model for pedestrians and vehicles based on YOLOv5 in PyTorch</li>\n<li>Deployed the model for 35 RTSP camera feeds installed in parking lots and housing communities of the Anacostia neighborhood in Washington, DC</li>\n<li>Implemented an audio detection pipeline based on YAMNet (MobileNet architecture) and created a trigger mechanism to detect gunshots in real-time</li>\n<li>Facilitated the storage of object counts along with color recognition for vehicles and integrated with gunshot detection and deployed the model on AWS EC2 instances using Amazon SageMaker</li>\n</ul>"}},{"node":{"frontmatter":{"title":"Graduate Teaching Assistant","company":"Virginia Tech","range":"August 2021 - Present","url":"https://ece.vt.edu/"},"html":"<ul>\n<li>Assisted a class of 70 students with Python/MATLAB programming assignments on image enhancement, compression, segmentation algorithms, and graded course projects for Digital Image Processing (Fall 2021)</li>\n<li>Streamlined the workflow and logistics for a graduate-level course on Advanced Computer Vision (Fall 2021)</li>\n<li>Assisted students with assignments and projects based on AI/ML for the course AI Innovation and Machine Learning with an enrollment of 60 students (Spring 2022, Spring 2023)</li>\n</ul>"}},{"node":{"frontmatter":{"title":"IoT Intern","company":"Makerdemy","range":"Jan - May 2021","url":"https://makerdemy.com/"},"html":"<ul>\n<li>Developed an end-to-end Home Automation system primarily for home security and thermostat functions using openHAB 3.0 and MQTT at Makerdemy, an EdTech start-up for the Internet-of-Things (IoT)</li>\n<li>Implemented various IoT projects with the ESP32 and Raspberry Pi 4 development boards</li>\n<li>Co-authored a course on designing home automation solutions from scratch and published it on Udemy and Teachable</li>\n</ul>"}}]},"featured":{"edges":[{"node":{"frontmatter":{"title":"Document Layout Analysis for ETDs","cover":{"childImageSharp":{"fluid":{"tracedSVG":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAMEAgX/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIQAxAAAAHurRgtJA//xAAXEAADAQAAAAAAAAAAAAAAAAAAARIQ/9oACAEBAAEFAsRbLZbP/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFBABAAAAAAAAAAAAAAAAAAAAIP/aAAgBAQAGPwJf/8QAGRABAAMBAQAAAAAAAAAAAAAAAAExYRFB/9oACAEBAAE/IfJcxSkjdD//2gAMAwEAAgADAAAAEGAP/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPxA//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAHBABAAMAAgMAAAAAAAAAAAAAAQARIUFRYXGR/9oACAEBAAE/EFaE2pbvcDyHtmh8QDl9jDW9n//Z","aspectRatio":1.5086206896551724,"src":"/static/5802268ff0f9b60a1baabc06cbc60f30/ea4ab/etd.jpg","srcSet":"/static/5802268ff0f9b60a1baabc06cbc60f30/477ba/etd.jpg 175w,\n/static/5802268ff0f9b60a1baabc06cbc60f30/06776/etd.jpg 350w,\n/static/5802268ff0f9b60a1baabc06cbc60f30/ea4ab/etd.jpg 700w,\n/static/5802268ff0f9b60a1baabc06cbc60f30/3055e/etd.jpg 1050w,\n/static/5802268ff0f9b60a1baabc06cbc60f30/5e5fc/etd.jpg 1355w","srcWebp":"/static/5802268ff0f9b60a1baabc06cbc60f30/89afa/etd.webp","srcSetWebp":"/static/5802268ff0f9b60a1baabc06cbc60f30/9fca7/etd.webp 175w,\n/static/5802268ff0f9b60a1baabc06cbc60f30/37a4e/etd.webp 350w,\n/static/5802268ff0f9b60a1baabc06cbc60f30/89afa/etd.webp 700w,\n/static/5802268ff0f9b60a1baabc06cbc60f30/78e7a/etd.webp 1050w,\n/static/5802268ff0f9b60a1baabc06cbc60f30/77b89/etd.webp 1355w","sizes":"(max-width: 700px) 100vw, 700px"}}},"tech":["YOLOv7","Detectron2","OCR","Docker","Flask","PostgreSQL","GitLab"],"github":"https://drive.google.com/file/d/10zjSSef_2ujy6anQg7kpoicZstHO1lrz/view?usp=share_link","external":"https://frontend.discovery.cs.vt.edu/"},"html":"<p>Developed an end-to-end object detection pipeline using YOLOv7 and Faster R-CNN (Detectron2) for information extraction from Virginia Tech’s Electronic Theses and Dissertations (ETD) repository. Integrated the model with a retrieval and search system that supports up to 50k ETDs</p>"}},{"node":{"frontmatter":{"title":"Text-to-Image Generation using GAN","cover":{"childImageSharp":{"fluid":{"tracedSVG":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAIDBP/EABYBAQEBAAAAAAAAAAAAAAAAAAACA//aAAwDAQACEAMQAAAB0os8q0EQ/8QAGhAAAgIDAAAAAAAAAAAAAAAAAAERIgISIf/aAAgBAQABBQK83LnXmtiWj//EABYRAQEBAAAAAAAAAAAAAAAAAAAREv/aAAgBAwEBPwGMv//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABwQAAICAgMAAAAAAAAAAAAAAAARASEyQUJxsf/aAAgBAQAGPwLZNSchxj6J9Fo//8QAGhABAAMBAQEAAAAAAAAAAAAAAQARIUExcf/aAAgBAQABPyFueZk0J9hU1cXwAt11QUegqnjVu5P/2gAMAwEAAgADAAAAEEMf/8QAFREBAQAAAAAAAAAAAAAAAAAAAHH/2gAIAQMBAT8Qaf/EABURAQEAAAAAAAAAAAAAAAAAAAAR/9oACAECAQE/EFf/xAAfEAEAAgIBBQEAAAAAAAAAAAABESEAMVFBYYGRocH/2gAIAQEAAT8QgSmaqj3+ZJBKAeq9+PzHAW5BMjVFsXQrgMLJoJ0mt85GKDNlvvP/2Q==","aspectRatio":1.3779527559055118,"src":"/static/ad3e59e8fc74041af43e3db48b8e260e/314ad/gan.jpg","srcSet":"/static/ad3e59e8fc74041af43e3db48b8e260e/477ba/gan.jpg 175w,\n/static/ad3e59e8fc74041af43e3db48b8e260e/06776/gan.jpg 350w,\n/static/ad3e59e8fc74041af43e3db48b8e260e/314ad/gan.jpg 455w","srcWebp":"/static/ad3e59e8fc74041af43e3db48b8e260e/6fb8d/gan.webp","srcSetWebp":"/static/ad3e59e8fc74041af43e3db48b8e260e/9fca7/gan.webp 175w,\n/static/ad3e59e8fc74041af43e3db48b8e260e/37a4e/gan.webp 350w,\n/static/ad3e59e8fc74041af43e3db48b8e260e/6fb8d/gan.webp 455w","sizes":"(max-width: 455px) 100vw, 455px"}}},"tech":["PyTorch","COCO","CUB","FID","IS"],"github":"https://github.com/nirmal-25/Text-to-Image-GAN","external":""},"html":"<p>Experimented with Generative Adversarial Networks (GAN) for text-to-image synthesis and implemented a lightweight model using deep fusion and text-guided image manipulation to reduce model parameters</p>"}},{"node":{"frontmatter":{"title":"Feature-based Visual Odometry","cover":{"childImageSharp":{"fluid":{"tracedSVG":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAKABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAABAACBf/EABUBAQEAAAAAAAAAAAAAAAAAAAEC/9oADAMBAAIQAxAAAAEauTsGQ6Z//8QAGxAAAwACAwAAAAAAAAAAAAAAAQIDABESIzH/2gAIAQEAAQUClYqaXbiqBxs4D1r5/8QAFxEBAAMAAAAAAAAAAAAAAAAAAAESUf/aAAgBAwEBPwFWdf/EABcRAQADAAAAAAAAAAAAAAAAAAABEVH/2gAIAQIBAT8BVOv/xAAaEAABBQEAAAAAAAAAAAAAAAABABARITFB/9oACAEBAAY/AqMBWd4FLFv/xAAZEAEAAwEBAAAAAAAAAAAAAAABABEhMUH/2gAIAQEAAT8h20hzOykpKaEGluIesRtV0gj/2gAMAwEAAgADAAAAEGTP/8QAGBEAAwEBAAAAAAAAAAAAAAAAAAERIaH/2gAIAQMBAT8Qao65wf/EABgRAAIDAAAAAAAAAAAAAAAAAAABEUGh/9oACAECAQE/EGpHXg//xAAcEAEAAgIDAQAAAAAAAAAAAAABABEhYTFBcaH/2gAIAQEAAT8Qq9Ak20acRtNP4WfsREHHFVqGCE10zZuTcDqcz//Z","aspectRatio":2.0833333333333335,"src":"/static/904c0427f5baa8e7e71fba5a1e3b4dd6/ca2cf/vo.jpg","srcSet":"/static/904c0427f5baa8e7e71fba5a1e3b4dd6/477ba/vo.jpg 175w,\n/static/904c0427f5baa8e7e71fba5a1e3b4dd6/06776/vo.jpg 350w,\n/static/904c0427f5baa8e7e71fba5a1e3b4dd6/ca2cf/vo.jpg 557w","srcWebp":"/static/904c0427f5baa8e7e71fba5a1e3b4dd6/59c97/vo.webp","srcSetWebp":"/static/904c0427f5baa8e7e71fba5a1e3b4dd6/9fca7/vo.webp 175w,\n/static/904c0427f5baa8e7e71fba5a1e3b4dd6/37a4e/vo.webp 350w,\n/static/904c0427f5baa8e7e71fba5a1e3b4dd6/59c97/vo.webp 557w","sizes":"(max-width: 557px) 100vw, 557px"}}},"tech":["OpenCV","KITTI","SLAM","SIFT"],"github":"https://github.com/nirmal-25/Feature-based-Monocular-Visual-Odometry","external":"https://nirmal-25.github.io/Feature-based-Monocular-Visual-Odometry/"},"html":"<p>Implemented a simplified Visual Odometry (VO) pipeline for monocular images using feature detector-descriptors and evaluated models on on the KITTI benchmark dataset</p>"}},{"node":{"frontmatter":{"title":"ADAS","cover":{"childImageSharp":{"fluid":{"tracedSVG":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAA7DAAAOwwHHb6hkAAADyklEQVQ4yyWQbUzUBRzH/5oKhzG4u8lxcA/++d//np+BOzjkeCYpFWE6glGx+ZC65hzGbGnLetN6UfSiRmPT0lSk0i1EsXBO8gHFbIkE5ELNMHQwtkSgm/n/NK4Xn5e/zz7fn3C4r43OawfoGjzK+bGTjMYusufDN2hsaaCXfo4/6eHKzFWe8ZCnyv/EmOAfZYKY8pA5ZZx55QFzygMeK/cQugY76B7q4MzwcS7cPcmf3GBLcwPmPDuFrY28PdrGickzxLjPrHKPWeUOc8ofzCvjzCn3mVHGmOY3JhllnEGE9p5WTvz0JaduHeHs8DFuPu5l0+56VvoksiwZjDw6x7+MMfXsVyYZijPNCNPKKFPKMI8Y4tb0BYZmfmRk/jLC0UvtfHv9C7pufsV3Px/i2lQPdVvWorVkEN1ey/m/Fqqv83vsEmPzF7kbu8Kd2BXGnvZznxvcjl1m6Ekf/Q+6uTrRg/D1tYPxwm8GDtB5tZ3321toPb6fyEu51O5az+fdH3Ck92MGJk/TP/s9fdPdDPx9loGJbg790Mr+T3dz7nYnp345zLG+zxA+6niPtz7ZSdHaMHXb1vLChkLebWvG5jWjTlWhN6qxWvTsO7GXcOdmKs43s/n0Hl5/82VsHjOinEG0Mpui1UGCeRJCcooKtTYJQRBYlriIDLOWjVvW0Niyj3VNTej0KYiSHm+5G1+ph/I1YcLFXgzmNGSHEcmmR6NOQqNNQq1NRMgvtREq8ZEp6UhQLSFVrcLpFdnQVMOOvfWUVYcpXRembmsVTc21vLKzmvqtZdS8mk9lbQ4bN0VxBiQ8IRmTRYfQsKOS3CIP4RIfZkmH2aAm6DHh9YpEKwM0bHuRpl21FJR5cXgMmCx6ZLeBsuoIa+qjRMqCVNWXUV4TJb/Ej2DITMVkVGM0pqJOSUCV+BwJSwVku57t7zQSrfBhcxtw58g4/VnYvWK8yOmTcAUkiqty2bC5iprXKqlYH0F4PnERaeoEMnXLSdctj/9Co0nELK4gr9iD1ZGJyazB5jHFBQsid7YVp1/GF7JhljOQ3SKizYDetAJh8WKBlOQlpK9QkSVqEEUNK0U1VocOm1OPy2fAEzDj9JnxZGcRjDgJFXvjMoc/C8lhwuJaiWQ3YhL1CEuXLkKrSSQ9LQlDZjKSrMXuTMftM+IJiPhDMv6wlewCZ5xVFUEKV2cTKfeTs8pFQXmA/FIfoaiH7IgLQaNZhi5dhcWahs2VGZ8oOwxItgWMyE4TruDCTAvuHAuBPHv8OBC2E4w4CEVd5Ba6COQ78IWt/Af7wVuPpcGeAgAAAABJRU5ErkJggg==","aspectRatio":1.4705882352941178,"src":"/static/3019ba0269304c1d0e80ef69d7523f37/fa75f/adas.png","srcSet":"/static/3019ba0269304c1d0e80ef69d7523f37/847ef/adas.png 175w,\n/static/3019ba0269304c1d0e80ef69d7523f37/91cba/adas.png 350w,\n/static/3019ba0269304c1d0e80ef69d7523f37/fa75f/adas.png 432w","srcWebp":"/static/3019ba0269304c1d0e80ef69d7523f37/d9974/adas.webp","srcSetWebp":"/static/3019ba0269304c1d0e80ef69d7523f37/9fca7/adas.webp 175w,\n/static/3019ba0269304c1d0e80ef69d7523f37/37a4e/adas.webp 350w,\n/static/3019ba0269304c1d0e80ef69d7523f37/d9974/adas.webp 432w","sizes":"(max-width: 432px) 100vw, 432px"}}},"tech":["TensorFlow","Faster R-CNN","YOLO","SGBM","BSTLD","TT100K"],"github":"https://github.com/nirmal-25/Advanced-Driver-Assistance-Systems-ADAS","external":""},"html":"<p>Developed a joint training pipeline for traffic light, traffic sign detection and car distance estimation (stereo vision) using 3 datasets consisting of over 50 classes using background thresholding</p>"}}]},"projects":{"edges":[{"node":{"frontmatter":{"title":"Few-Shot Learning in Non-Euclidean Space","tech":["PyTorch","TensorFlow","mini-ImageNet","Omniglot"],"github":"https://github.com/nirmal-25/Few-Shot-Classification-Meta","external":""},"html":"<p>Developed few-shot image classification models in Non-Euclidean space, and evaluated using Stiefel, Hyperbolic and Riemannian optimizers for faster convergence</p>"}},{"node":{"frontmatter":{"title":"Image Captioning using RNN","tech":["TensorFlow","LSTM","VizWiz-Captions"],"github":"https://github.com/nirmal-25/Image-Captioning-RNN","external":""},"html":"<p>LSTM (RNN) implementation for image captioning on VizWiz-Captions dataset. Used GLOVE model for word embedding and an Inception V3 model pretrained on ImageNet for transfer learning</p>"}},{"node":{"frontmatter":{"title":"Introduction to openHAB 3.0","tech":["OpenHAB 3.0","Raspberry Pi","ESP32","MQTT"],"github":"","external":"https://www.udemy.com/course/introduction-to-openhab-3/"},"html":"<p>Co-authored a course on <a href=\"https://www.openhab.org/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">openHAB</a> intended to teach enthusiasts to design home automation solutions using development boards and published it on <a href=\"https://www.udemy.com/course/introduction-to-openhab-3/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Udemy</a> and <a href=\"https://makerdemy1.teachable.com/p/introduction-to-openhab-3-0\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Teachable</a></p>"}},{"node":{"frontmatter":{"title":"UHF RFID Sterile Garment Tracking System","tech":["RFID","ESP8266","ATmega328P","nRF24L01"],"github":"","external":"https://drive.google.com/file/d/14tZWhhqBOTfrWrfwQgtUMuzqx5tljV59/view?usp=sharing"},"html":"<p>Spearheaded a team of six to victory at <a href=\"https://drive.google.com/file/d/1m76CQKyKU6ZZ80ql2kz16JW1PsXJvUkp/view?usp=share_link\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Smart India Hackathon</a> and secured a grant of 10 Lakh INR for technology business incubation under <a href=\"https://www.sanofi.com/en/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Sanofi</a></p>\n<!-- for designing RFID tags to track sterile garment wash cycle in a healthcare laundry facility -->"}}]},"contact":{"edges":[{"node":{"frontmatter":{"title":"Let's Get In Touch","buttonText":"Say Hello"},"html":"<p>Feel free to reach out via mail or LinkedIn!</p>"}}]}},"pageContext":{}},"staticQueryHashes":["3115057458"]}